{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_openml\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(image):\n",
    "    # Garantir que a imagem seja uint8\n",
    "    image_uint8 = image.astype(np.uint8)\n",
    " \n",
    "    # Gaussian Blur para reduzir ruído\n",
    "    image_blurred = cv2.GaussianBlur(image_uint8, (5, 5), 0)\n",
    "\n",
    "    # Binarização usando Otsu\n",
    "    _, image_binarized = cv2.threshold(image_blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Encontrar o contorno principal\n",
    "    contours, _ = cv2.findContours(image_binarized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        # Encontrar bounding box do maior contorno\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        cropped = image_binarized[y:y+h, x:x+w]\n",
    "        \n",
    "        # Redimensionar o número para 20x20\n",
    "        digit_resized = cv2.resize(cropped, (20, 20), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Adicionar padding para ficar 28x28\n",
    "        padded = cv2.copyMakeBorder(digit_resized, 4, 4, 4, 4, cv2.BORDER_CONSTANT, value=0)\n",
    "    else:\n",
    "        padded = np.zeros((28, 28), dtype=np.uint8)  # Caso não encontre contornos\n",
    "\n",
    "    # Normalizar para [0, 1]\n",
    "    image_normalized = padded / 255.0\n",
    "    \n",
    "    return image_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (3000, 28, 28), (3000,)\n",
      "Test set: (1000, 28, 28), (1000,)\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_mnist():\n",
    "    # Load the MNIST dataset from OpenML\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    x, y = mnist.data, mnist.target.astype(int)\n",
    "\n",
    "    # Select 3000 samples for training and 1000 for testing\n",
    "    x_train, y_train = x[:3000], y[:3000]\n",
    "    x_test, y_test = x[3000:4000], y[3000:4000]\n",
    "\n",
    "    # Reshape the images to 28x28\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    x_train_processed = np.array([preprocess_mnist(image) for image in x_train])\n",
    "    x_test_processed = np.array([preprocess_mnist(image) for image in x_test])\n",
    "    \n",
    "    return (x_train_processed, y_train), (x_test_processed, y_test)\n",
    "\n",
    "# Chamada da função\n",
    "try:\n",
    "    (x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n",
    "\n",
    "    # Verifica os formatos dos arrays\n",
    "    print(f\"Train set: {x_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Test set: {x_test.shape}, {y_test.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm(x_train, y_train, x_test, y_test):\n",
    "    model = SVC(C=10, gamma=0.001, kernel=\"rbf\", probability=True)  # Enable probability predictions\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path=\"svm_model.joblib\"):\n",
    "    joblib.dump({\"model\": model}, path)\n",
    "    print(f\"Model exported to {path}\")\n",
    "\n",
    "# Load a saved model\n",
    "def load_model(path=\"svm_model.joblib\"):\n",
    "    data = joblib.load(path)\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return data[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(image, title, folder=\"images\"):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{folder}/{title}.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "def read_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    save_plot(image_rgb, \"Original\")\n",
    "    return image_rgb\n",
    "\n",
    "# Step 1: Grayscale Conversion\n",
    "def convert_to_grayscale(image_rgb):\n",
    "    grayscale_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    save_plot(grayscale_image, \"Grayscale\")\n",
    "    return grayscale_image\n",
    "\n",
    "# Step 2: Noise Reduction using a Gaussian and Median Blur\n",
    "def reduce_noise(grayscale_image):\n",
    "    gaussian_blurred = cv2.GaussianBlur(grayscale_image, (3, 3), 0)\n",
    "    denoised_image = cv2.medianBlur(gaussian_blurred, 3)\n",
    "    save_plot(denoised_image, \"Denoised\")\n",
    "    return denoised_image\n",
    "\n",
    "# Step 3: Binarization\n",
    "def binarize_image(denoised_image):\n",
    "    _, binarized_image = cv2.threshold(denoised_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    save_plot(binarized_image, \"Binarized\")\n",
    "    return binarized_image\n",
    "\n",
    "# Step 4: Color Inversion\n",
    "def invert_colors(binarized_image):\n",
    "    inverted_image = cv2.bitwise_not(binarized_image)\n",
    "    save_plot(inverted_image, \"Inverted\")\n",
    "    return inverted_image\n",
    "\n",
    "# Step 5: Resize\n",
    "def resize_image(inverted_image):\n",
    "    contours, _ = cv2.findContours(inverted_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "        cropped = inverted_image[y:y+h, x:x+w]\n",
    "        digit_resized = cv2.resize(cropped, (20, 20), interpolation=cv2.INTER_AREA)\n",
    "        resized_image = cv2.copyMakeBorder(digit_resized, 4, 4, 4, 4, cv2.BORDER_CONSTANT, value=0)\n",
    "    else:\n",
    "        resized_image = np.zeros((28, 28), dtype=np.uint8)\n",
    "    save_plot(resized_image, \"Resized (28x28)\")\n",
    "    return resized_image\n",
    "\n",
    "# Step 6: Normalize Pixels\n",
    "def normalize_pixels(resized_image):\n",
    "    normalized_pixels = resized_image / 255.0\n",
    "    save_plot(normalized_pixels, \"Normalized\")\n",
    "    return normalized_pixels\n",
    "\n",
    "# Step 6: Enhance thickness\n",
    "def enhance_thickness(normalized_pixels):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    thickened_image = cv2.dilate(normalized_pixels, kernel, iterations=1)\n",
    "    save_plot(thickened_image, \"Thickened\")\n",
    "    return thickened_image\n",
    "\n",
    "# Step 7: Standardize Pixels\n",
    "def standardize_pixels(thickened_image, scaler_mean, scaler_scale):\n",
    "    flattened = thickened_image.flatten()\n",
    "    standardized_pixels = (flattened - scaler_mean) / scaler_scale\n",
    "    standardized_pixels_reshaped = standardized_pixels.reshape(28, 28)\n",
    "    save_plot(standardized_pixels_reshaped, \"Standardized\")\n",
    "    return standardized_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, scaler_mean=np.zeros(28*28), scaler_scale=np.ones(28*28)):\n",
    "    image_rgb = read_image(image_path)\n",
    "    grayscale_image = convert_to_grayscale(image_rgb)\n",
    "    denoised_image = reduce_noise(grayscale_image)\n",
    "    binarized_image = binarize_image(denoised_image)\n",
    "    inverted_image = invert_colors(binarized_image)\n",
    "    resized_image = resize_image(inverted_image)\n",
    "    normalized_pixels = normalize_pixels(resized_image)\n",
    "    thickened_image = enhance_thickness(normalized_pixels)\n",
    "    standardized_pixels = standardize_pixels(thickened_image, scaler_mean, scaler_scale)\n",
    "    return standardized_pixels\n",
    "\n",
    "def process_and_predict_images(folder_path, model):\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not image_files:\n",
    "        print(\"No images found in the provided folder.\")\n",
    "        return\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        try:\n",
    "            image_normalized = preprocess_image(image_path)\n",
    "            image_flattened = image_normalized.reshape(1, -1)  # Flatten the standardized image\n",
    "            prediction = model.predict(image_flattened)[0]\n",
    "\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            plt.imshow(image_normalized.reshape(28, 28), cmap='gray')\n",
    "            plt.title(f\"Predicted: {prediction}\")\n",
    "            plt.savefig(f\"{\"Predicted\"}.png\", bbox_inches='tight', pad_inches=0)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  3000\n",
      "Test size:  1000\n",
      "Accuracy: 0.9390\n",
      "Model exported to svm_model2.joblib\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(\"Train size: \",np.shape(x_train)[0])\n",
    "print(\"Test size: \",np.shape(x_test)[0])\n",
    "\n",
    "model = train_and_evaluate_svm(x_train, y_train, x_test, y_test)\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from svm_model2.joblib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAADCCAYAAADQOvnPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAANmUlEQVR4nO3dfUyV9fsH8DfEgZMHCIcIgnooCA5m5tACmzM1CzLJWOQsm8cHsi0zQ4db6x+MnC2tYa22lIBcDHNJtlhJVkhzYOrGlprLovCpoKJIC8pzDtf3D8f5Rfd9kGfOxe/92vjDi+u+z4fD2w/307nvABERECkTONIDIOoPBpdUYnBJJQaXVGJwSSUGl1RicEklBpdUYnBJJb8NbllZGQICArxfQUFBmDhxIlauXImLFy8Oyxji4+OxYsUK778PHTqEgIAAHDp0qE/rqaurQ0FBAdra2gZ1fACwYsUKxMfH93v53NxcTJ06FREREbj++uuRlJSE/Px8/Prrr4M3yCEQNNIDuJbS0lI4HA50dHTgiy++wNatW1FbW4sTJ07AZrMN61hSU1NRX1+PKVOm9Gm5uro6bN68GStWrEBERMTQDK6f/vrrL6xZswaJiYmwWq04fvw4tmzZgo8++ggNDQ0IDg4e6SGa8vvgTp06FTNnzgQAzJs3Dx6PB4WFhdi/fz+WLVtmukx7ezvGjBkz6GMJDw9Henr6oK93JFVUVHT79/z58xEWFoYnn3wShw8fxvz580doZD3z200FX7qCc/bsWQBX/1SGhobixIkTuPfeexEWFoa7774bAHDlyhW88MILcDgcCAkJQVRUFFauXIlffvml2zpdLhc2bdqEmJgYjBkzBrNnz8bRo0cNr+1rU+HLL79EVlYWIiMjYbVakZCQgGeeeQYAUFBQgPz8fADAjTfe6N30+fc63n33XcyaNQs2mw2hoaHIyMhAQ0OD4fXLysqQnJyMkJAQpKSkYPfu3f16D68lKioKABAU5Mfzmvip0tJSASDHjh3rVt+xY4cAkJ07d4qIiNPpFIvFIvHx8bJ161b57LPPpLq6Wjwej2RmZorNZpPNmzfLwYMHpbi4WOLi4mTKlCnS3t7uXafT6ZSAgADJz8+XTz75RF555RWJi4uT8PBwcTqd3r6amhoBIDU1Nd7agQMHxGKxyLRp06SsrEw+//xzKSkpkaVLl4qIyPnz52XdunUCQCorK6W+vl7q6+vljz/+EBGRLVu2SEBAgKxatUqqqqqksrJSZs2aJTabTU6dOmV4PxYvXiwffvihvPPOO5KYmCiTJk0Su93e7T1yOp0CQH744Ydev98ul0v+/PNPOXz4sDgcDpk9e7a43e5eLz/c/D64R44cEZfLJZcvX5aqqiqJioqSsLAwaW5uFpH/+yWVlJR0W76iokIAyL59+7rVjx07JgDkjTfeEBGR06dPCwDJy8vr1ldeXi4ArhnchIQESUhIkI6ODp8/y7Zt20yDdO7cOQkKCpJ169Z1q1++fFliYmJkyZIlIiLi8XgkNjZWUlNTpbOz09vX1NQkFovFENxVq1bJddddJ01NTT7H9G/19fUCwPu1cOFCuXTpUq+WHSl+v6mQnp4Oi8WCsLAwLFq0CDExMfj4448RHR3dre+hhx7q9u+qqipEREQgKysLbrfb+zV9+nTExMR4/1TX1NQAgGF7ecmSJdf8U3nmzBk0NjZi9erVsFqtff7Zqqur4Xa7sXz58m5jtFqtuOuuu7xj/Oabb/Djjz/i0UcfRUBAgHd5u92OO++807Det956C263G3a7vVfjuPXWW3Hs2DHU1tZix44daGhowD333IP29vY+/0zDxY83Yq7avXs3UlJSEBQUhOjoaEyYMMHQM2bMGISHh3ertbS0oK2tzedecdfhntbWVgBATExMt+8HBQUhMjKyx7F1bStPnDixdz/Mf7S0tAAAbr/9dtPvBwYG9jjGrlpTU1O/Xr+LzWbz7gDPmTMHaWlpSE9Px5tvvom8vLwBrXuo+H1wU1JSvG+qL/+ehbqMGzcOkZGROHDggOkyYWFhAOANZ3NzM+Li4rzfd7vd3sD40rUTc+HChR77fBk3bhwA4L333utxdvz3GP/LrDZQM2fORGBgIM6cOTPo6x4sfh/c/lq0aBH27NkDj8eDtLQ0n31z584FAJSXl2PGjBne+t69e+F2u3t8jaSkJCQkJKCkpAQbNmxASEiIaV9XvaOjo1s9IyMDQUFBaGxsNGzq/FtycjImTJiAiooKbNiwwfsf9ezZs6irq0NsbGyP4+yr2tpadHZ2IjExcVDXO5hGbXCXLl2K8vJyLFy4EOvXr8cdd9wBi8WCCxcuoKamBosXL0Z2djZSUlLw2GOPoaioCBaLBQsWLMDJkyexfft2w+aHmddffx1ZWVlIT09HXl4eJk+ejHPnzqG6uhrl5eUArm5DAsCOHTvgdDphsViQnJyM+Ph4PP/883juuefw/fffIzMzE2PHjkVLSwuOHj0Km82GzZs3IzAwEIWFhcjNzUV2djYef/xxtLW1oaCgwHTzYfXq1Xj77bfR2NjY40xeVVWFXbt24YEHHoDdbofL5cLx48dRVFSExMRE5Obm9vPdHwYjvXfoi6/DYf/ldDrFZrOZfs/lcsn27dvltttuE6vVKqGhoeJwOOSJJ56Qb7/91tv3zz//yMaNG2X8+PFitVolPT1d6uvrxW63X/OogsjVvfL77rtPbrjhBgkJCZGEhATDUYpnn31WYmNjJTAw0LCO/fv3y7x58yQ8PFxCQkLEbrdLTk6OfPrpp93WUVxcLDfffLMEBwdLUlKSlJSUiNPp7PfhsNOnT0tOTo7Y7XaxWq1itVrF4XBIfn6+tLa29rjsSAsQ4ad8SR+/PxxGZIbBJZUYXFKJwSWVGFxSicEllRhcUqnXZ87MrgcgGmy9Pa3AGZdUYnBJJQaXVGJwSSUGl1RicEklBpdUYnBJJQaXVGJwSSUGl1RicEklBpdUYnBJJQaXVBrxO9kkJycbanPmzDHtnT59eq+WB2D6XARfN7ELDQ31PcBe8Hg8pvUrV64Yar7uR3by5ElDzdezJj744AND7bvvvuthhKMPZ1xSicEllRhcUonBJZUYXFKp13drHOinfH09d+zgwYOG2kD38gGYPrzPH44qdN0JfSDMfmWlpaWmvWvXrjXU/v777wGPYajwU740qjG4pBKDSyoxuKTSiJ/ypb4z21FetWqVae/YsWMNNV9P+NH0VAXOuKQSg0sqMbikEoNLKjG4pNKoPapQX19vqB05csS09+uvvzbUfv75Z9Pe8ePHG2q+nhX84IMP9rp3qGRnZxtqGRkZpr2+HtjtjzjjkkoMLqnE4JJKDC6pNGzX49JVTz/9tGm9qKjIUBuq9zwnJ8e0vm/fviF5vb7g9bg0qjG4pBKDSyoxuKQSg0sqjdpTvv5q165dpvXly5cbajNmzBjq4ajFGZdUYnBJJQaXVGJwSSXunA0hu91uqFVUVJj2ckesbzjjkkoMLqnE4JJKDC6pxOCSSryQvI/Mbsy8fv16095NmzYZamY3nAaAwMChmUNOnz5tqPk6gtHR0TEkY+gLXkhOoxqDSyoxuKQSg0sqjdpTviEhIYbauHHjTHunTZtmqPn6JOzDDz9sqA3Gk3QGymwnDAAyMzMNNX/YCRsozrikEoNLKjG4pBKDSyoxuKTSsB1ViImJMa07nU5D7ZZbbjHtTUpKMtRuuukm016zIwj+fNq6s7Oz173FxcWG2vvvv2/ae/HixX6PyZ9xxiWVGFxSicEllRhcUmnYds4sFotp3exZs/8fud1uQy04ONi0d82aNb2qAUBjY6Ohlp+fb9rrawfPH3HGJZUYXFKJwSWVGFxSicEllUbtheR0VUJCgqFWWVlp2rtz505D7amnnjLtdblcAxvYAHHGJZUYXFKJwSWVGFxSadhuwTRp0iTT+tq1awe0Xo/HY1r/6aefDLWWlpZe95qdKgXM3wdf1wSnpqYaagsWLDDtzcjIMNR8nfIdTnv37jWtP/LII4ZaX64p9oW3YKJRjcEllRhcUonBJZUYXFKJN3b2E5MnTzbUXn75ZdNeX/c1G05mN7N+9dVXB7xeHlWgUY3BJZUYXFKJwSWVuHOm0MaNGw21bdu2mfYO1e/N7JR4YmLigNfLnTMa1RhcUonBJZUYXFKJwSWVeFRhlHjppZdM677uEzYUBiMjPKpAoxqDSyoxuKQSg0sqcedslLDZbKb15uZmQy00NHRIxsCdM6JrYHBJJQaXVGJwSSUGl1TijZ0Vcjgchtprr71m2jtURxBGGmdcUonBJZUYXFKJwSWVhm3nLD4+3rSekpIyoPX6OkX422+/GWpmz8v1xdcNo81ez9cOUHh4uKHm69nFZk/Huf/++01709LSTOvD6auvvhrR1+eMSyoxuKQSg0sqMbikEoNLKg3bUYXCwkLT+ty5cw216Oho016LxTKYQxpyHR0dhtqlS5dMe3///XdDra2tbbCH1Gfnz583rS9btmyYR9IdZ1xSicEllRhcUonBJZV4Pe4oZ3aKurW11bS3pKTEUHvxxRdNe812JocTZ1xSicEllRhcUonBJZUYXFKJRxX8mK8L3/fs2WOonTp1yrT38OHDhlpdXZ1pr8vl6sPoRhZnXFKJwSWVGFxSicEllXhjZ/IrvLEzjWoMLqnE4JJKDC6pxOCSSgwuqcTgkkoMLqnE4JJKDC6pxOCSSgwuqcTgkkoMLqnE4JJKDC6p1OtP+fb2Al+i4cAZl1RicEklBpdUYnBJJQaXVGJwSSUGl1RicEklBpdU+h/H3p6Wyb6ZQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model() ##\n",
    "\n",
    "folder_path = \"Images\"  # Replace with your folder path\n",
    "process_and_predict_images(folder_path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
